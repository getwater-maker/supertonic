import os
import platform

# Pillow í˜¸í™˜ì„± íŒ¨ì¹˜ (ANTIALIAS -> LANCZOS)
from PIL import Image
if not hasattr(Image, 'ANTIALIAS'):
    Image.ANTIALIAS = Image.LANCZOS

# ImageMagick ì„¤ì • (í”Œë«í¼ë³„ ìë™ ê°ì§€)
if platform.system() == 'Windows':
    # Windows: ì¼ë°˜ì ì¸ ì„¤ì¹˜ ê²½ë¡œë“¤
    imagemagick_paths = [
        r'C:\Program Files\ImageMagick-7.1.2-Q16-HDRI\magick.exe',
        r'C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe',
        r'C:\Program Files\ImageMagick-7.1.0-Q16-HDRI\magick.exe',
        r'C:\Program Files\ImageMagick\magick.exe',
        r'C:\Program Files (x86)\ImageMagick\magick.exe',
    ]
    for path in imagemagick_paths:
        if os.path.exists(path):
            os.environ['IMAGEMAGICK_BINARY'] = path
            break
else:
    # Linux/Mac
    os.environ['IMAGEMAGICK_BINARY'] = '/usr/bin/convert'

import gradio as gr
import sys
import datetime
import numpy as np
import re
import tempfile

# ìƒìœ„ í´ë”ì˜ py ëª¨ë“ˆ ì‚¬ìš©ì„ ìœ„í•´ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'py'))

from helper import load_text_to_speech, load_voice_style, chunk_text  # type: ignore
import soundfile as sf
from docx import Document

# ì „ì—­ ë³€ìˆ˜
tts_model = None
whisper_model = None
ASSETS_DIR = os.path.join(os.path.dirname(__file__), '..', 'assets')
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), 'outputs')
TEMP_DIR = os.path.join(os.path.dirname(__file__), 'temp')
FONTS_DIR = os.path.join(ASSETS_DIR, 'fonts')

# ì¶œë ¥ í´ë” ìƒì„±
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(TEMP_DIR, exist_ok=True)
os.makedirs(FONTS_DIR, exist_ok=True)


def ensure_korean_font():
    """í•œê¸€ í°íŠ¸ê°€ ì—†ìœ¼ë©´ ì„¤ì¹˜ - TTF ìš°ì„ """
    font_path = os.path.join(FONTS_DIR, 'NotoSansKR-Bold.ttf')

    # ì´ë¯¸ í°íŠ¸ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
    if os.path.exists(font_path) and os.path.getsize(font_path) > 100000:
        print(f"í•œê¸€ í°íŠ¸ í™•ì¸ë¨: {font_path}")
        return font_path

    # TTF ì‹œìŠ¤í…œ í°íŠ¸ ìš°ì„  í™•ì¸ (PILì—ì„œ ì§ì ‘ ë¡œë“œ ê°€ëŠ¥)
    ttf_fonts = [
        '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf',
        '/usr/share/fonts/nanum/NanumGothicBold.ttf',
        '/usr/share/fonts/truetype/noto/NotoSansKR-Bold.ttf',
        '/usr/share/fonts/opentype/noto/NotoSansKR-Bold.otf',
        'C:/Windows/Fonts/NotoSansKR-Bold.ttf',
        'C:/Windows/Fonts/malgunbd.ttf',
    ]

    for sys_font in ttf_fonts:
        if os.path.exists(sys_font):
            print(f"ì‹œìŠ¤í…œ TTF í°íŠ¸ ë°œê²¬: {sys_font}")
            return sys_font

    # TTC í°íŠ¸ (PILì—ì„œ index í•„ìš”)
    ttc_fonts = [
        '/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc',
        '/usr/share/fonts/noto-cjk/NotoSansCJK-Bold.ttc',
        '/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc',
        '/usr/share/fonts/google-noto-cjk/NotoSansCJK-Bold.ttc',
    ]

    for sys_font in ttc_fonts:
        if os.path.exists(sys_font):
            print(f"ì‹œìŠ¤í…œ TTC í°íŠ¸ ë°œê²¬: {sys_font}")
            return sys_font

    # Linuxì—ì„œ aptë¡œ ì„¤ì¹˜ ì‹œë„
    print("í•œê¸€ í°íŠ¸ ì„¤ì¹˜ ì‹œë„ ì¤‘...")
    try:
        import subprocess
        # fonts-nanum ì„¤ì¹˜ (TTF íŒŒì¼ ì œê³µ)
        subprocess.run(
            ['apt-get', 'install', '-y', 'fonts-nanum'],
            capture_output=True, text=True, timeout=120
        )
        # fc-cache ì‹¤í–‰
        subprocess.run(['fc-cache', '-f', '-v'], capture_output=True, timeout=60)

        # ì„¤ì¹˜ í›„ TTF ë‹¤ì‹œ í™•ì¸
        for sys_font in ttf_fonts:
            if os.path.exists(sys_font):
                print(f"apt ì„¤ì¹˜ í›„ TTF í°íŠ¸ ë°œê²¬: {sys_font}")
                return sys_font

        # TTC í™•ì¸
        for sys_font in ttc_fonts:
            if os.path.exists(sys_font):
                print(f"apt ì„¤ì¹˜ í›„ TTC í°íŠ¸ ë°œê²¬: {sys_font}")
                return sys_font
    except Exception as e:
        print(f"apt ì„¤ì¹˜ ì‹¤íŒ¨: {e}")

    # pipë¡œ í°íŠ¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹œë„
    try:
        import subprocess
        subprocess.run([sys.executable, '-m', 'pip', 'install', 'fonts', 'font-noto-sans-kr'],
                      capture_output=True, timeout=60)
    except Exception as e:
        print(f"pip í°íŠ¸ ì„¤ì¹˜ ì‹¤íŒ¨: {e}")

    # ë‹¤ìš´ë¡œë“œ ì‹œë„ (ì—¬ëŸ¬ URL)
    font_urls = [
        "https://raw.githubusercontent.com/nickmass/font-patcher/main/fonts/NotoSansKR-Bold.ttf",
        "https://cdn.jsdelivr.net/gh/nickmass/font-patcher/fonts/NotoSansKR-Bold.ttf",
    ]

    for font_url in font_urls:
        try:
            import urllib.request
            print(f"í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹œë„: {font_url}")
            urllib.request.urlretrieve(font_url, font_path)
            if os.path.exists(font_path) and os.path.getsize(font_path) > 100000:
                print(f"í•œê¸€ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {font_path}")
                return font_path
        except Exception as e:
            print(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue

    print("ê²½ê³ : í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    return None


# ì•± ì‹œì‘ ì‹œ í°íŠ¸ í™•ì¸
KOREAN_FONT_PATH = ensure_korean_font()


def check_gpu_available():
    """GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            print(f"GPU ê°ì§€ë¨: {gpu_name}")
            return True
    except ImportError:
        pass
    print("GPU ì—†ìŒ - CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    return False


def init_tts(use_gpu=False):
    """TTS ëª¨ë¸ ì´ˆê¸°í™” (CPU ëª¨ë“œ ê¸°ë³¸)"""
    global tts_model
    if tts_model is None:
        onnx_dir = os.path.join(ASSETS_DIR, 'onnx')
        tts_model = load_text_to_speech(onnx_dir, use_gpu=use_gpu)
        mode = "GPU" if use_gpu else "CPU"
        print(f"TTS ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ({mode})")
    return tts_model


def init_whisper():
    """Whisper ëª¨ë¸ ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)"""
    global whisper_model
    if whisper_model is None:
        import whisper  # type: ignore
        print("Whisper ëª¨ë¸ ë¡œë“œ ì¤‘...")
        whisper_model = whisper.load_model("base")
        print("Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    return whisper_model


def analyze_audio_with_whisper(audio_path, language='ko'):
    """Whisperë¡œ ì˜¤ë””ì˜¤ ë¶„ì„í•˜ì—¬ ë‹¨ì–´/êµ¬ê°„ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ"""
    model = init_whisper()

    lang_map = {
        'ko': 'ko', 'en': 'en', 'es': 'es', 'pt': 'pt', 'fr': 'fr'
    }
    whisper_lang = lang_map.get(language, 'ko')

    result = model.transcribe(
        audio_path,
        language=whisper_lang,
        word_timestamps=True,
        verbose=False
    )
    return result


def match_subtitles_to_audio(whisper_result, subtitle_lines, audio_duration):
    """Whisper ë¶„ì„ ê²°ê³¼ì™€ ìë§‰ í…ìŠ¤íŠ¸ë¥¼ ë§¤ì¹­í•˜ì—¬ íƒ€ì„ì½”ë“œ ìƒì„±

    Whisper ì„¸ê·¸ë¨¼íŠ¸ì˜ ì‹œì‘/ë ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ìë§‰ ë¼ì¸ì„ ê· ë“± ë°°ë¶„
    """
    subtitle_timings = []
    segments = whisper_result.get('segments', [])

    if not subtitle_lines:
        return subtitle_timings

    total_lines = len(subtitle_lines)

    # Whisper ì„¸ê·¸ë¨¼íŠ¸ê°€ ìˆìœ¼ë©´ ì„¸ê·¸ë¨¼íŠ¸ ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ ë°°ë¶„
    if segments:
        # ì „ì²´ ìŒì„± êµ¬ê°„ (ì²« ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘ ~ ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ë)
        speech_start = segments[0]['start']
        speech_end = segments[-1]['end']
        speech_duration = speech_end - speech_start

        # ê° ìë§‰ ë¼ì¸ì˜ ê¸¸ì´(ê¸€ììˆ˜) ê¸°ë°˜ìœ¼ë¡œ ì‹œê°„ ë°°ë¶„
        line_lengths = [len(line) for line in subtitle_lines]
        total_chars = sum(line_lengths)

        current_time = speech_start
        for i, line in enumerate(subtitle_lines):
            # ê¸€ì ìˆ˜ ë¹„ìœ¨ë¡œ ì‹œê°„ ë°°ë¶„
            char_ratio = line_lengths[i] / total_chars if total_chars > 0 else 1 / total_lines
            line_duration = speech_duration * char_ratio

            # ìµœì†Œ 0.5ì´ˆ, ìµœëŒ€ëŠ” ì œí•œ ì—†ìŒ
            line_duration = max(0.5, line_duration)

            start_time = current_time
            end_time = min(current_time + line_duration, audio_duration)

            subtitle_timings.append({
                'text': line,
                'start': start_time,
                'end': end_time
            })

            current_time = end_time

            print(f"ìë§‰ íƒ€ì´ë°: [{start_time:.2f}s - {end_time:.2f}s] {line[:30]}")
    else:
        # Whisper ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìœ¼ë©´ ê· ë“± ë¶„ë°°
        time_per_line = audio_duration / total_lines
        for i, line in enumerate(subtitle_lines):
            subtitle_timings.append({
                'text': line,
                'start': i * time_per_line,
                'end': (i + 1) * time_per_line
            })

    # ë§ˆì§€ë§‰ ìë§‰ì€ ì˜¤ë””ì˜¤ ëê¹Œì§€
    if subtitle_timings:
        subtitle_timings[-1]['end'] = audio_duration

    return subtitle_timings


def get_max_length(lang):
    """ì–¸ì–´ë³„ ìµœëŒ€ ì²­í¬ ê¸¸ì´ ë°˜í™˜ (Supertonic ì •ì±…)"""
    return 120 if lang == "ko" else 300


def get_voice_list():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ë°˜í™˜"""
    voice_dir = os.path.join(ASSETS_DIR, 'voice_styles')
    voices = []

    if os.path.exists(voice_dir):
        for f in sorted(os.listdir(voice_dir)):
            if f.endswith('.json'):
                name = f.replace('.json', '')
                label = f"ì—¬ì„± {name[1]}" if name.startswith('F') else f"ë‚¨ì„± {name[1]}"
                voices.append(f"{label} ({name})")

    return voices


def get_voice_file(voice_label):
    """ìŒì„± ë¼ë²¨ì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ"""
    # "ì—¬ì„± 1 (F1)" -> "F1.json"
    match = re.search(r'\(([^)]+)\)', voice_label)
    if match:
        return f"{match.group(1)}.json"
    return "F1.json"


def read_text_file(file_path):
    """TXT ë˜ëŠ” DOCX íŒŒì¼ ì½ê¸°"""
    if file_path is None:
        return ""

    ext = os.path.splitext(file_path)[1].lower()

    try:
        if ext == '.txt':
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        elif ext == '.docx':
            doc = Document(file_path)
            return '\n'.join([para.text for para in doc.paragraphs if para.text.strip()])
        else:
            return f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {ext}"
    except Exception as e:
        return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}"


def synthesize_speech(text, voice_label, language, speed, total_step, progress=gr.Progress(), output_name=None):
    """ìŒì„± í•©ì„±"""
    if not text or not text.strip():
        return None, "í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."

    try:
        progress(0.05, desc="í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘...")

        voice_file = get_voice_file(voice_label)
        max_len = get_max_length(language)
        chunks = chunk_text(text, max_len=max_len)
        total_chunks = len(chunks) if chunks else 1

        progress(0.15, desc="TTS ëª¨ë¸ ë¡œë“œ ì¤‘...")
        tts = init_tts()

        voice_path = os.path.join(ASSETS_DIR, 'voice_styles', voice_file)
        style = load_voice_style([voice_path], verbose=False)

        all_audio = []
        total_duration = 0.0

        for i, chunk in enumerate(chunks):
            if not chunk.strip():
                continue

            prog = 0.2 + (i / total_chunks) * 0.6
            preview = chunk[:30] + '...' if len(chunk) > 30 else chunk
            progress(prog, desc=f'[{i + 1}/{total_chunks}] {preview}')

            wav, duration = tts(chunk, language, style, int(total_step), float(speed))
            w = wav[0, :int(tts.sample_rate * duration[0].item())]
            all_audio.append(w)
            total_duration += duration[0].item()

            if i < total_chunks - 1:
                silence = np.zeros(int(0.3 * tts.sample_rate), dtype=np.float32)
                all_audio.append(silence)
                total_duration += 0.3

        progress(0.85, desc="ì˜¤ë””ì˜¤ ë³‘í•© ì¤‘...")

        if len(all_audio) > 1:
            combined = np.concatenate(all_audio)
        else:
            combined = all_audio[0] if all_audio else np.array([], dtype=np.float32)

        progress(0.90, desc="íŒŒì¼ ì €ì¥ ì¤‘...")
        # ì¶œë ¥ íŒŒì¼ëª…: ëŒ€ë³¸ íŒŒì¼ëª… ë˜ëŠ” íƒ€ì„ìŠ¤íƒ¬í”„
        if output_name:
            filename = f"{output_name}.wav"
        else:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"tts_{timestamp}.wav"
        filepath = os.path.join(OUTPUT_DIR, filename)

        sf.write(filepath, combined, tts.sample_rate)

        progress(1.0, desc="ì™„ë£Œ!")

        return filepath, f"âœ… ìŒì„± ìƒì„± ì™„ë£Œ!\níŒŒì¼: {filename}\nê¸¸ì´: {total_duration:.1f}ì´ˆ"

    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def create_video(tts_text, subtitle_text, voice_label, language, speed, total_step,
                 background_file, resolution, font_size, subtitle_position,
                 subtitle_offset_x, subtitle_offset_y,
                 use_subtitle_bg, subtitle_bg_opacity, subtitle_bg_padding,
                 progress=gr.Progress(), output_name=None):
    """ì˜ìƒ ìƒì„±"""
    print(f"=== create_video í˜¸ì¶œ ===")
    print(f"use_subtitle_bg={use_subtitle_bg} (type={type(use_subtitle_bg)})")
    print(f"subtitle_position={subtitle_position}, offset_x={subtitle_offset_x}%, offset_y={subtitle_offset_y}%")
    print(f"font_size={font_size}, opacity={subtitle_bg_opacity}, padding={subtitle_bg_padding}")

    if not tts_text or not tts_text.strip():
        return None, "TTS í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."

    if not subtitle_text or not subtitle_text.strip():
        subtitle_text = tts_text

    # ê¸°ë³¸ê°’ ì²˜ë¦¬ (Noneì´ê±°ë‚˜ ë²”ìœ„ ë°–ì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    try:
        font_size = int(font_size) if font_size is not None else 70
        if font_size < 10 or font_size > 200:
            font_size = 70
    except (ValueError, TypeError):
        font_size = 70

    try:
        subtitle_bg_opacity = float(subtitle_bg_opacity) if subtitle_bg_opacity is not None else 0.6
        if subtitle_bg_opacity < 0.1 or subtitle_bg_opacity > 1.0:
            subtitle_bg_opacity = 0.6
    except (ValueError, TypeError):
        subtitle_bg_opacity = 0.6

    try:
        subtitle_bg_padding = int(subtitle_bg_padding) if subtitle_bg_padding is not None else 20
        if subtitle_bg_padding < 0 or subtitle_bg_padding > 100:
            subtitle_bg_padding = 20
    except (ValueError, TypeError):
        subtitle_bg_padding = 20

    # X/Y ì˜¤í”„ì…‹ ì²˜ë¦¬ (% ë‹¨ìœ„, -50 ~ 50 ë²”ìœ„)
    try:
        subtitle_offset_x = float(subtitle_offset_x) if subtitle_offset_x is not None else 0
        if subtitle_offset_x < -50 or subtitle_offset_x > 50:
            subtitle_offset_x = 0
    except (ValueError, TypeError):
        subtitle_offset_x = 0

    try:
        subtitle_offset_y = float(subtitle_offset_y) if subtitle_offset_y is not None else 0
        if subtitle_offset_y < -50 or subtitle_offset_y > 50:
            subtitle_offset_y = 0
    except (ValueError, TypeError):
        subtitle_offset_y = 0

    resolution = resolution if resolution else "1920x1080"

    try:
        from moviepy.editor import (  # type: ignore
            ImageClip, VideoFileClip, AudioFileClip,
            CompositeVideoClip, ColorClip
        )

        progress(0.05, desc="ì¤€ë¹„ ì¤‘...")

        video_width, video_height = map(int, resolution.split('x'))
        voice_file = get_voice_file(voice_label)

        # ë°°ê²½ íŒŒì¼ ì²˜ë¦¬
        background_path = None
        background_type = None
        if background_file is not None:
            background_path = background_file
            ext = os.path.splitext(background_file)[1].lower()
            if ext in ['.mp4', '.avi', '.mov', '.mkv', '.webm']:
                background_type = 'video'
            else:
                background_type = 'image'

        # ìŒì„± ìƒì„±
        progress(0.10, desc="TTS ëª¨ë¸ ë¡œë“œ ì¤‘...")
        tts = init_tts()

        voice_path = os.path.join(ASSETS_DIR, 'voice_styles', voice_file)
        style = load_voice_style([voice_path], verbose=False)

        max_len = get_max_length(language)
        chunks = chunk_text(tts_text, max_len=max_len)
        if not chunks:
            chunks = [tts_text]

        total_chunks = len(chunks)
        all_audio = []
        audio_duration = 0.0

        for i, chunk in enumerate(chunks):
            if not chunk.strip():
                continue

            prog = 0.15 + (i / total_chunks) * 0.25
            preview = chunk[:20] + '...' if len(chunk) > 20 else chunk
            progress(prog, desc=f'ìŒì„± [{i + 1}/{total_chunks}] {preview}')

            wav, duration = tts(chunk, language, style, int(total_step), float(speed))
            w = wav[0, :int(tts.sample_rate * duration[0].item())]
            all_audio.append(w)
            audio_duration += duration[0].item()

            if i < total_chunks - 1:
                silence = np.zeros(int(0.3 * tts.sample_rate), dtype=np.float32)
                all_audio.append(silence)
                audio_duration += 0.3

        if len(all_audio) > 1:
            combined_audio = np.concatenate(all_audio)
        else:
            combined_audio = all_audio[0] if all_audio else np.array([], dtype=np.float32)

        progress(0.40, desc="ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ì¤‘...")
        temp_audio_path = os.path.join(TEMP_DIR, "temp_audio.wav")
        sf.write(temp_audio_path, combined_audio, tts.sample_rate)

        # Whisper ë¶„ì„
        progress(0.42, desc="Whisper ëª¨ë¸ ë¡œë“œ ì¤‘...")
        subtitle_lines = [line.strip() for line in subtitle_text.split('\n') if line.strip()]

        if subtitle_lines:
            progress(0.45, desc="ìŒì„± ë¶„ì„ ì¤‘... (Whisper)")
            try:
                whisper_result = analyze_audio_with_whisper(temp_audio_path, language)
                progress(0.50, desc="ìë§‰ íƒ€ì„ì½”ë“œ ìƒì„± ì¤‘...")
                subtitle_timings = match_subtitles_to_audio(
                    whisper_result, subtitle_lines, audio_duration
                )
            except Exception as e:
                print(f"Whisper ë¶„ì„ ì‹¤íŒ¨, ê· ë“± ë¶„ë°° ì‚¬ìš©: {e}")
                time_per_line = audio_duration / len(subtitle_lines)
                subtitle_timings = [
                    {'text': line, 'start': i * time_per_line, 'end': (i + 1) * time_per_line}
                    for i, line in enumerate(subtitle_lines)
                ]
        else:
            subtitle_timings = []

        # ë°°ê²½ í´ë¦½ ìƒì„±
        progress(0.55, desc="ë°°ê²½ ì˜ìƒ ì¤€ë¹„ ì¤‘...")

        if background_path and background_type == 'video':
            bg_clip = VideoFileClip(background_path)
            if bg_clip.duration < audio_duration:
                bg_clip = bg_clip.loop(duration=audio_duration)
            else:
                bg_clip = bg_clip.subclip(0, audio_duration)
            bg_clip = bg_clip.resize((video_width, video_height))
        elif background_path and background_type == 'image':
            bg_clip = ImageClip(background_path).set_duration(audio_duration)
            bg_clip = bg_clip.resize((video_width, video_height))
        else:
            bg_clip = ColorClip(size=(video_width, video_height), color=(26, 26, 46)).set_duration(audio_duration)

        # ìë§‰ ìœ„ì¹˜ ê³„ì‚°
        def get_subtitle_pos(pos, width, height, fsize, offset_x_pct, offset_y_pct):
            """ìë§‰ ìœ„ì¹˜ ê³„ì‚° (ì˜¤í”„ì…‹ì€ í•´ìƒë„ì˜ % ë‹¨ìœ„)"""
            margin = 50
            # ì˜¤í”„ì…‹ í”½ì…€ ê³„ì‚° (í•´ìƒë„ì˜ %)
            offset_x_px = int(width * offset_x_pct / 100)
            offset_y_px = int(height * offset_y_pct / 100)

            positions = {
                'ìƒë‹¨-ì™¼ìª½': (margin, margin),
                'ìƒë‹¨-ì¤‘ì•™': ('center', margin),
                'ìƒë‹¨-ì˜¤ë¥¸ìª½': (width - margin, margin),
                'ì¤‘ì•™-ì™¼ìª½': (margin, 'center'),
                'ì¤‘ì•™': ('center', 'center'),
                'ì¤‘ì•™-ì˜¤ë¥¸ìª½': (width - margin, 'center'),
                'í•˜ë‹¨-ì™¼ìª½': (margin, height - margin - fsize),
                'í•˜ë‹¨-ì¤‘ì•™': ('center', height - margin - fsize),
                'í•˜ë‹¨-ì˜¤ë¥¸ìª½': (width - margin, height - margin - fsize),
            }
            base_pos = positions.get(pos, ('center', height - margin - fsize))

            # ì˜¤í”„ì…‹ ì ìš© (centerì¸ ê²½ìš° í”½ì…€ë¡œ ë³€í™˜ í›„ ì˜¤í”„ì…‹ ì ìš©)
            final_x = base_pos[0]
            final_y = base_pos[1]

            if final_x == 'center':
                final_x = width // 2 + offset_x_px
            else:
                final_x = final_x + offset_x_px

            if final_y == 'center':
                final_y = height // 2 + offset_y_px
            else:
                final_y = final_y + offset_y_px

            return (final_x, final_y)

        txt_position = get_subtitle_pos(subtitle_position, video_width, video_height, font_size, subtitle_offset_x, subtitle_offset_y)

        # ìë§‰ í´ë¦½ ìƒì„± (PIL ê¸°ë°˜ - ImageMagick í°íŠ¸ ë¬¸ì œ ìš°íšŒ)
        progress(0.60, desc="ìë§‰ í´ë¦½ ìƒì„± ì¤‘...")
        subtitle_clips = []

        # PIL í°íŠ¸ ë¡œë“œ (í•œ ë²ˆë§Œ)
        from PIL import Image as PILImage, ImageDraw, ImageFont

        # í°íŠ¸ ì°¾ê¸° - TTF ìš°ì„ 
        font_candidates = [
            os.path.join(FONTS_DIR, 'NotoSansKR-Bold.ttf'),
            '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf',
            '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
            '/usr/share/fonts/truetype/noto/NotoSansKR-Bold.ttf',
            'C:/Windows/Fonts/NotoSansKR-Bold.ttf',
            'C:/Windows/Fonts/malgunbd.ttf',
        ]
        ttc_candidates = [
            '/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc',
            '/usr/share/fonts/noto-cjk/NotoSansCJK-Bold.ttc',
        ]

        pil_font = None
        for font_path in font_candidates:
            if os.path.exists(font_path):
                try:
                    pil_font = ImageFont.truetype(font_path, font_size)
                    print(f"PIL í°íŠ¸ ë¡œë“œ ì„±ê³µ (TTF): {font_path}")
                    break
                except Exception as e:
                    print(f"TTF í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {font_path} - {e}")

        if pil_font is None:
            for font_path in ttc_candidates:
                if os.path.exists(font_path):
                    try:
                        pil_font = ImageFont.truetype(font_path, font_size, index=1)
                        print(f"PIL í°íŠ¸ ë¡œë“œ ì„±ê³µ (TTC): {font_path}")
                        break
                    except Exception as e:
                        print(f"TTC í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {font_path} - {e}")

        if pil_font is None:
            print("ëª¨ë“  í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
            pil_font = ImageFont.load_default()

        for i, timing in enumerate(subtitle_timings):
            line = timing['text']
            start_time = timing['start']
            end_time = timing['end']

            if not line:
                continue

            if i % 5 == 0:
                prog = 0.60 + (i / len(subtitle_timings)) * 0.15
                progress(prog, desc=f'ìë§‰ í´ë¦½ [{i + 1}/{len(subtitle_timings)}]')

            try:
                # PILë¡œ ìë§‰ ì´ë¯¸ì§€ ìƒì„±
                # í…ìŠ¤íŠ¸ í¬ê¸° ì¸¡ì •
                dummy_img = PILImage.new('RGBA', (1, 1))
                dummy_draw = ImageDraw.Draw(dummy_img)
                bbox = dummy_draw.textbbox((0, 0), line, font=pil_font)
                text_width = bbox[2] - bbox[0]
                text_height = bbox[3] - bbox[1]

                # ì™¸ê³½ì„  ë‘ê»˜
                outline_width = 3
                padding = int(subtitle_bg_padding) if use_subtitle_bg else 10

                # ì´ë¯¸ì§€ í¬ê¸°: ìë§‰ ë°°ê²½ ì‚¬ìš© ì‹œ í™”ë©´ ì „ì²´ ë„ˆë¹„
                if use_subtitle_bg:
                    img_width = video_width
                    img_height = text_height + padding * 2 + outline_width * 2
                else:
                    img_width = text_width + outline_width * 2 + 20
                    img_height = text_height + outline_width * 2 + 10

                # RGBA ì´ë¯¸ì§€ ìƒì„± (íˆ¬ëª… ë°°ê²½)
                subtitle_img = PILImage.new('RGBA', (img_width, img_height), (0, 0, 0, 0))
                draw = ImageDraw.Draw(subtitle_img)

                # ìë§‰ ë°°ê²½ ë°•ìŠ¤ (ì„ íƒì )
                if use_subtitle_bg:
                    alpha = int(255 * subtitle_bg_opacity)
                    draw.rectangle([0, 0, img_width, img_height], fill=(0, 0, 0, alpha))

                # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚° (ì´ë¯¸ì§€ ë‚´ ì¤‘ì•™)
                text_x = (img_width - text_width) // 2
                text_y = (img_height - text_height) // 2

                # ì™¸ê³½ì„  (ê²€ì •)
                for dx in range(-outline_width, outline_width + 1):
                    for dy in range(-outline_width, outline_width + 1):
                        if dx != 0 or dy != 0:
                            draw.text((text_x + dx, text_y + dy), line, font=pil_font, fill=(0, 0, 0, 255))

                # ë³¸ë¬¸ (í°ìƒ‰)
                draw.text((text_x, text_y), line, font=pil_font, fill=(255, 255, 255, 255))

                # PIL ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
                img_array = np.array(subtitle_img)

                # ImageClip ìƒì„±
                txt_clip = ImageClip(img_array, ismask=False, transparent=True)
                txt_clip = txt_clip.set_duration(end_time - start_time)

                # ìë§‰ ìœ„ì¹˜ ê³„ì‚°
                if use_subtitle_bg:
                    # ë°°ê²½ ì‚¬ìš© ì‹œ: ê°€ë¡œëŠ” 0 (ì „ì²´ ë„ˆë¹„), ì„¸ë¡œëŠ” txt_position ê¸°ì¤€
                    clip_x = 0
                    if txt_position[1] == 'center':
                        clip_y = (video_height - img_height) // 2
                    else:
                        clip_y = txt_position[1] - padding if isinstance(txt_position[1], int) else video_height - img_height - 50
                else:
                    # ë°°ê²½ ë¯¸ì‚¬ìš© ì‹œ: txt_position ê¸°ì¤€
                    if txt_position[0] == 'center':
                        clip_x = (video_width - img_width) // 2
                    else:
                        clip_x = txt_position[0] if isinstance(txt_position[0], int) else 50

                    if txt_position[1] == 'center':
                        clip_y = (video_height - img_height) // 2
                    else:
                        clip_y = txt_position[1] if isinstance(txt_position[1], int) else video_height - img_height - 50

                txt_clip = txt_clip.set_position((clip_x, clip_y))
                txt_clip = txt_clip.set_start(start_time).set_end(end_time)
                subtitle_clips.append(txt_clip)
                print(f"ìë§‰ ì¶”ê°€ (PIL): [{start_time:.2f}s - {end_time:.2f}s] {line[:20]}...")

            except Exception as e:
                import traceback
                print(f"ìë§‰ í´ë¦½ ìƒì„± ì‹¤íŒ¨ [{i}]: {e}")
                traceback.print_exc()

        print(f"ì´ ìë§‰ í´ë¦½ ìˆ˜: {len(subtitle_clips)}")
        progress(0.75, desc="ì˜ìƒ í•©ì„± ì¤‘...")
        final_clip = CompositeVideoClip([bg_clip] + subtitle_clips)

        progress(0.78, desc="ì˜¤ë””ì˜¤ ì¶”ê°€ ì¤‘...")
        audio_clip = AudioFileClip(temp_audio_path)
        final_clip = final_clip.set_audio(audio_clip)

        progress(0.80, desc="ì˜ìƒ ì¸ì½”ë”© ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        # ì¶œë ¥ íŒŒì¼ëª…: ëŒ€ë³¸ íŒŒì¼ëª… ë˜ëŠ” íƒ€ì„ìŠ¤íƒ¬í”„
        if output_name:
            filename = f"{output_name}.mp4"
        else:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"video_{timestamp}.mp4"
        filepath = os.path.join(OUTPUT_DIR, filename)

        final_clip.write_videofile(
            filepath,
            fps=30,
            codec='libx264',
            audio_codec='aac',
            verbose=False,
            logger=None
        )

        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        final_clip.close()
        audio_clip.close()
        if background_path and background_type == 'video':
            bg_clip.close()

        if os.path.exists(temp_audio_path):
            os.remove(temp_audio_path)

        progress(1.0, desc="ì™„ë£Œ!")

        return filepath, f"âœ… ì˜ìƒ ìƒì„± ì™„ë£Œ!\níŒŒì¼: {filename}\nê¸¸ì´: {audio_duration:.1f}ì´ˆ"

    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def load_tts_text(file):
    """TTS í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ"""
    if file is None:
        return ""
    return read_text_file(file.name)


def load_subtitle_text(file):
    """ìë§‰ í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ"""
    if file is None:
        return ""
    return read_text_file(file.name)


def generate_preview(subtitle_text, background_file, resolution, font_size, subtitle_position,
                     subtitle_offset_x, subtitle_offset_y,
                     use_subtitle_bg, subtitle_bg_opacity, subtitle_bg_padding):
    """ìë§‰ì´ í¬í•¨ëœ ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ìƒì„±"""
    try:
        from PIL import Image, ImageDraw, ImageFont

        # ê¸°ë³¸ê°’ ì²˜ë¦¬ (Noneì´ê±°ë‚˜ ë²”ìœ„ ë°–ì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        try:
            font_size = int(font_size) if font_size is not None else 70
            if font_size < 10 or font_size > 200:
                font_size = 70
        except (ValueError, TypeError):
            font_size = 70

        try:
            subtitle_bg_opacity = float(subtitle_bg_opacity) if subtitle_bg_opacity is not None else 0.6
            if subtitle_bg_opacity < 0.1 or subtitle_bg_opacity > 1.0:
                subtitle_bg_opacity = 0.6
        except (ValueError, TypeError):
            subtitle_bg_opacity = 0.6

        try:
            subtitle_bg_padding = int(subtitle_bg_padding) if subtitle_bg_padding is not None else 20
            if subtitle_bg_padding < 0 or subtitle_bg_padding > 100:
                subtitle_bg_padding = 20
        except (ValueError, TypeError):
            subtitle_bg_padding = 20

        # X/Y ì˜¤í”„ì…‹ ì²˜ë¦¬ (% ë‹¨ìœ„)
        try:
            subtitle_offset_x = float(subtitle_offset_x) if subtitle_offset_x is not None else 0
            if subtitle_offset_x < -50 or subtitle_offset_x > 50:
                subtitle_offset_x = 0
        except (ValueError, TypeError):
            subtitle_offset_x = 0

        try:
            subtitle_offset_y = float(subtitle_offset_y) if subtitle_offset_y is not None else 0
            if subtitle_offset_y < -50 or subtitle_offset_y > 50:
                subtitle_offset_y = 0
        except (ValueError, TypeError):
            subtitle_offset_y = 0

        resolution = resolution if resolution else "1920x1080"

        video_width, video_height = map(int, resolution.split('x'))

        # ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
        if background_file is not None:
            ext = os.path.splitext(background_file.name)[1].lower()
            if ext in ['.mp4', '.avi', '.mov', '.mkv', '.webm']:
                # ì˜ìƒì—ì„œ ì²« í”„ë ˆì„ ì¶”ì¶œ
                from moviepy.editor import VideoFileClip
                clip = VideoFileClip(background_file.name)
                frame = clip.get_frame(0)
                clip.close()
                bg_img = Image.fromarray(frame)
                bg_img = bg_img.resize((video_width, video_height), Image.LANCZOS)
            else:
                # ì´ë¯¸ì§€ íŒŒì¼
                bg_img = Image.open(background_file.name)
                bg_img = bg_img.resize((video_width, video_height), Image.LANCZOS)
                bg_img = bg_img.convert('RGBA')
        else:
            # ê¸°ë³¸ ë°°ê²½ (ì–´ë‘ìš´ ìƒ‰)
            bg_img = Image.new('RGBA', (video_width, video_height), (26, 26, 46, 255))

        # ìë§‰ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        if not subtitle_text or not subtitle_text.strip():
            subtitle_text = "ìë§‰ ë¯¸ë¦¬ë³´ê¸° í…ìŠ¤íŠ¸"

        # ì²« ë²ˆì§¸ ì¤„ë§Œ ë¯¸ë¦¬ë³´ê¸°ì— í‘œì‹œ
        first_line = subtitle_text.strip().split('\n')[0]

        # í°íŠ¸ ì°¾ê¸° - TTF ìš°ì„ , TTCëŠ” ì¸ë±ìŠ¤ í•„ìš”
        font_candidates = [
            # TTF íŒŒì¼ ìš°ì„  (PILì—ì„œ ì§ì ‘ ë¡œë“œ ê°€ëŠ¥)
            os.path.join(FONTS_DIR, 'NotoSansKR-Bold.ttf'),
            '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf',
            '/usr/share/fonts/truetype/noto/NotoSansKR-Bold.ttf',
            'C:/Windows/Fonts/NotoSansKR-Bold.ttf',
            'C:/Windows/Fonts/malgunbd.ttf',
        ]

        # TTC íŒŒì¼ (ì¸ë±ìŠ¤ í•„ìš”)
        ttc_candidates = [
            '/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc',
            '/usr/share/fonts/noto-cjk/NotoSansCJK-Bold.ttc',
        ]

        font = None

        # TTF ë¨¼ì € ì‹œë„
        for font_path in font_candidates:
            if os.path.exists(font_path):
                try:
                    font = ImageFont.truetype(font_path, font_size)
                    print(f"ë¯¸ë¦¬ë³´ê¸° í°íŠ¸ ë¡œë“œ ì„±ê³µ (TTF): {font_path}")
                    break
                except Exception as e:
                    print(f"TTF í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {font_path} - {e}")
                    continue

        # TTF ì‹¤íŒ¨ì‹œ TTC ì‹œë„ (ì¸ë±ìŠ¤ 0 = í•œêµ­ì–´)
        if font is None:
            for font_path in ttc_candidates:
                if os.path.exists(font_path):
                    try:
                        font = ImageFont.truetype(font_path, font_size, index=1)  # index 1 = Korean
                        print(f"ë¯¸ë¦¬ë³´ê¸° í°íŠ¸ ë¡œë“œ ì„±ê³µ (TTC): {font_path}")
                        break
                    except Exception as e:
                        print(f"TTC í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {font_path} - {e}")
                        continue

        # ëª¨ë‘ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ í°íŠ¸
        if font is None:
            print("ëª¨ë“  í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
            font = ImageFont.load_default()

        draw = ImageDraw.Draw(bg_img)

        # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
        bbox = draw.textbbox((0, 0), first_line, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]

        # ìë§‰ ìœ„ì¹˜ ê³„ì‚°
        margin = 50
        # ì˜¤í”„ì…‹ í”½ì…€ ê³„ì‚° (í•´ìƒë„ì˜ %)
        offset_x_px = int(video_width * subtitle_offset_x / 100)
        offset_y_px = int(video_height * subtitle_offset_y / 100)

        positions = {
            'ìƒë‹¨-ì™¼ìª½': (margin, margin),
            'ìƒë‹¨-ì¤‘ì•™': ((video_width - text_width) // 2, margin),
            'ìƒë‹¨-ì˜¤ë¥¸ìª½': (video_width - text_width - margin, margin),
            'ì¤‘ì•™-ì™¼ìª½': (margin, (video_height - text_height) // 2),
            'ì¤‘ì•™': ((video_width - text_width) // 2, (video_height - text_height) // 2),
            'ì¤‘ì•™-ì˜¤ë¥¸ìª½': (video_width - text_width - margin, (video_height - text_height) // 2),
            'í•˜ë‹¨-ì™¼ìª½': (margin, video_height - text_height - margin),
            'í•˜ë‹¨-ì¤‘ì•™': ((video_width - text_width) // 2, video_height - text_height - margin),
            'í•˜ë‹¨-ì˜¤ë¥¸ìª½': (video_width - text_width - margin, video_height - text_height - margin),
        }
        base_x, base_y = positions.get(subtitle_position, positions['í•˜ë‹¨-ì¤‘ì•™'])
        # ì˜¤í”„ì…‹ ì ìš©
        text_x = base_x + offset_x_px
        text_y = base_y + offset_y_px

        # ìë§‰ ë°°ê²½ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (í™”ë©´ ì „ì²´ ë„ˆë¹„, ìë§‰ ë†’ì´ + íŒ¨ë”©)
        if use_subtitle_bg:
            padding = int(subtitle_bg_padding)
            # ê°€ë¡œ: í™”ë©´ ì „ì²´ + ì—¬ìœ , ì„¸ë¡œ: ìë§‰ ë†’ì´ + íŒ¨ë”©*2
            bg_h = text_height + padding * 2
            bg_x1 = -5
            bg_x2 = video_width + 5

            # ë°°ê²½ ë°•ìŠ¤ì˜ Y ìœ„ì¹˜ ê³„ì‚° (ìë§‰ì´ ë°•ìŠ¤ ì •ì¤‘ì•™ì— ì˜¤ë„ë¡)
            bg_y1 = text_y - padding
            bg_y2 = bg_y1 + bg_h

            # ë°˜íˆ¬ëª… ë°°ê²½
            overlay = Image.new('RGBA', bg_img.size, (0, 0, 0, 0))
            overlay_draw = ImageDraw.Draw(overlay)
            alpha = int(255 * subtitle_bg_opacity)
            overlay_draw.rectangle([bg_x1, bg_y1, bg_x2, bg_y2], fill=(0, 0, 0, alpha))
            bg_img = Image.alpha_composite(bg_img.convert('RGBA'), overlay)

        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (ê²€ì • ì™¸ê³½ì„  + í°ìƒ‰ ë³¸ë¬¸)
        draw = ImageDraw.Draw(bg_img)

        # ì™¸ê³½ì„  (ê²€ì •, ë‘ê»˜ 3)
        outline_width = 3
        for dx in range(-outline_width, outline_width + 1):
            for dy in range(-outline_width, outline_width + 1):
                if dx != 0 or dy != 0:
                    draw.text((text_x + dx, text_y + dy), first_line, font=font, fill=(0, 0, 0, 255))

        # ë³¸ë¬¸ (í°ìƒ‰ ê³ ì •)
        draw.text((text_x, text_y), first_line, font=font, fill=(255, 255, 255, 255))

        # ë¯¸ë¦¬ë³´ê¸° ì €ì¥
        preview_path = os.path.join(TEMP_DIR, "preview.png")
        bg_img.convert('RGB').save(preview_path)

        return preview_path

    except Exception as e:
        import traceback
        traceback.print_exc()
        return None


# Gradio UI êµ¬ì„± (ì‹¬í”Œ ë””ìì¸)
def create_ui():
    voices = get_voice_list()
    if not voices:
        voices = ["ìŒì„± íŒŒì¼ ì—†ìŒ"]

    languages = ["í•œêµ­ì–´", "English", "EspaÃ±ol", "PortuguÃªs", "FranÃ§ais"]

    resolutions = ["1920x1080", "1280x720", "3840x2160", "1080x1920", "720x1280"]

    subtitle_positions = ["ì¤‘ì•™", "í•˜ë‹¨-ì¤‘ì•™", "ìƒë‹¨-ì¤‘ì•™"]

    with gr.Blocks(title="Supertonic TTS") as demo:
        gr.Markdown("# Supertonic TTS")

        # 1í–‰: íŒŒì¼ ì—…ë¡œë“œ (ëŒ€ë³¸, ìë§‰, ë°°ê²½)
        with gr.Row():
            tts_file = gr.File(
                label="ëŒ€ë³¸ íŒŒì¼ (TXT/DOCX)",
                file_types=[".txt", ".docx"]
            )
            subtitle_file = gr.File(
                label="ìë§‰ íŒŒì¼ (TXT/DOCX)",
                file_types=[".txt", ".docx"]
            )
            background_file = gr.File(
                label="ë°°ê²½ (ì´ë¯¸ì§€/ì˜ìƒ)",
                file_types=["image", "video"]
            )

        # 2í–‰: í…ìŠ¤íŠ¸ ì…ë ¥ + ë¯¸ë¦¬ë³´ê¸°
        with gr.Row():
            tts_text = gr.Textbox(
                label="ëŒ€ë³¸ (ìŒì„± ë³€í™˜ìš©)",
                placeholder="ìŒì„±ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì²¨ë¶€í•˜ì„¸ìš”...",
                lines=10
            )
            subtitle_text = gr.Textbox(
                label="ìë§‰ (ë¹„ì›Œë‘ë©´ ëŒ€ë³¸ ì‚¬ìš©)",
                placeholder="í™”ë©´ì— í‘œì‹œë  ìë§‰...",
                lines=10
            )
            preview_image = gr.Image(label="ë¯¸ë¦¬ë³´ê¸°", height=280)

        # 3í–‰: ìŒì„± ì„¤ì • + ì˜ìƒ ì„¤ì • + ìƒíƒœ + ìƒì„±ë²„íŠ¼ (í•œ ì¤„)
        with gr.Row():
            voice_select = gr.Dropdown(choices=voices, value=voices[0] if voices else None, label="ìŒì„±", scale=2)
            speed_slider = gr.Number(value=1.0, label="ì†ë„", minimum=0.5, maximum=2.0, step=0.1, scale=1)
            lang_select = gr.Dropdown(choices=languages, value="í•œêµ­ì–´", label="ì–¸ì–´", scale=1)
            step_slider = gr.Number(value=5, label="í’ˆì§ˆ", minimum=1, maximum=10, step=1, scale=1)
            # ì˜ìƒ ì„¤ì • (ë°°ê²½ ì²¨ë¶€ ì‹œë§Œ ì‚¬ìš©ë¨)
            resolution_select = gr.Dropdown(choices=resolutions, value="1920x1080", label="í•´ìƒë„", visible=False, scale=2)
            font_size_slider = gr.Number(value=70, label="í°íŠ¸", step=5, visible=False, scale=1)
            position_select = gr.Dropdown(choices=subtitle_positions, value="ì¤‘ì•™", label="ìë§‰ìœ„ì¹˜", visible=False, scale=2)
            subtitle_offset_x = gr.Number(value=0, label="Xì˜¤í”„ì…‹(%)", step=1, visible=False, scale=1)
            subtitle_offset_y = gr.Number(value=0, label="Yì˜¤í”„ì…‹(%)", step=1, visible=False, scale=1)
            use_subtitle_bg = gr.Checkbox(label="ìë§‰ë°°ê²½ ì‚¬ìš©", value=True, visible=False, scale=2, min_width=120)
            subtitle_bg_opacity = gr.Number(value=0.6, label="íˆ¬ëª…ë„", step=0.1, visible=False, scale=1)
            subtitle_bg_padding = gr.Number(value=20, label="ì—¬ë°±", step=5, visible=False, scale=1)
            status_output = gr.Textbox(label="ìƒíƒœ", interactive=False, scale=2)
            generate_btn = gr.Button("ìƒì„±í•˜ê¸°", variant="primary", scale=1)

        # 4í–‰: ê²°ê³¼
        with gr.Row():
            audio_output = gr.Audio(label="ê²°ê³¼ ìŒì„±", type="filepath")
            video_output = gr.Video(label="ê²°ê³¼ ì˜ìƒ", visible=False)

        # ë‹¤ìš´ë¡œë“œ íŒŒì¼ (Kaggleìš©)
        with gr.Row():
            download_file = gr.File(label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ", visible=False)

        # ì´ë²¤íŠ¸ ì—°ê²°
        def get_lang_code(lang_name):
            lang_map = {"í•œêµ­ì–´": "ko", "English": "en", "EspaÃ±ol": "es", "PortuguÃªs": "pt", "FranÃ§ais": "fr"}
            return lang_map.get(lang_name, "ko")

        # ë°°ê²½ íŒŒì¼ ì²¨ë¶€ ì‹œ ì˜ìƒ ì„¤ì • í‘œì‹œ/ìˆ¨ê¹€
        def toggle_video_settings(file):
            visible = file is not None
            return [gr.update(visible=visible)] * 9  # 8ê°œ ì˜ìƒì„¤ì • + 1ê°œ ì˜ìƒì¶œë ¥

        background_file.change(
            fn=toggle_video_settings,
            inputs=[background_file],
            outputs=[resolution_select, font_size_slider, position_select,
                     subtitle_offset_x, subtitle_offset_y,
                     use_subtitle_bg, subtitle_bg_opacity, subtitle_bg_padding, video_output]
        )

        # ë¯¸ë¦¬ë³´ê¸° ì…ë ¥ ì»´í¬ë„ŒíŠ¸ ë¦¬ìŠ¤íŠ¸
        preview_inputs = [
            subtitle_text, background_file, resolution_select,
            font_size_slider, position_select,
            subtitle_offset_x, subtitle_offset_y,
            use_subtitle_bg, subtitle_bg_opacity, subtitle_bg_padding
        ]

        # ì‹¤ì‹œê°„ ë¯¸ë¦¬ë³´ê¸°: ì„¤ì • ë³€ê²½ ì‹œ ìë™ ì—…ë°ì´íŠ¸
        for component in [position_select, use_subtitle_bg, resolution_select]:
            component.change(
                fn=generate_preview,
                inputs=preview_inputs,
                outputs=[preview_image]
            )

        for num_input in [font_size_slider, subtitle_bg_opacity, subtitle_bg_padding, subtitle_offset_x, subtitle_offset_y]:
            num_input.change(
                fn=generate_preview,
                inputs=preview_inputs,
                outputs=[preview_image]
            )

        background_file.change(
            fn=generate_preview,
            inputs=preview_inputs,
            outputs=[preview_image]
        )

        subtitle_text.blur(
            fn=generate_preview,
            inputs=preview_inputs,
            outputs=[preview_image]
        )

        # íŒŒì¼ ì—…ë¡œë“œ ì‹œ í…ìŠ¤íŠ¸ ìë™ ë¡œë“œ
        tts_file.change(
            fn=load_tts_text,
            inputs=[tts_file],
            outputs=[tts_text]
        )

        subtitle_file.change(
            fn=load_subtitle_text,
            inputs=[subtitle_file],
            outputs=[subtitle_text]
        )

        # ìƒì„± ë²„íŠ¼ í´ë¦­
        def generate_content(tts_txt, sub_txt, voice, lang, speed, step,
                             bg_file, res, font, pos, offset_x, offset_y,
                             use_bg, bg_opacity, bg_pad, script_file):
            lang_code = get_lang_code(lang)

            # ì¶œë ¥ íŒŒì¼ëª… ê²°ì • (ëŒ€ë³¸ íŒŒì¼ëª… ê¸°ë°˜)
            if script_file is not None:
                base_name = os.path.splitext(os.path.basename(script_file.name))[0]
            else:
                base_name = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')

            if bg_file is not None:
                # ì˜ìƒ ìƒì„±
                video_path, status = create_video(
                    tts_txt, sub_txt, voice, lang_code, speed, step,
                    bg_file.name, res, font, pos, offset_x, offset_y,
                    use_bg, bg_opacity, bg_pad,
                    output_name=base_name
                )
                # ë‹¤ìš´ë¡œë“œ íŒŒì¼ë„ í•¨ê»˜ ë°˜í™˜
                return None, video_path, status, gr.update(value=video_path, visible=True) if video_path else gr.update(visible=False)
            else:
                # ìŒì„±ë§Œ ìƒì„±
                audio_path, status = synthesize_speech(
                    tts_txt, voice, lang_code, speed, step,
                    output_name=base_name
                )
                # ë‹¤ìš´ë¡œë“œ íŒŒì¼ë„ í•¨ê»˜ ë°˜í™˜
                return audio_path, None, status, gr.update(value=audio_path, visible=True) if audio_path else gr.update(visible=False)

        generate_btn.click(
            fn=generate_content,
            inputs=[
                tts_text, subtitle_text, voice_select, lang_select,
                speed_slider, step_slider, background_file, resolution_select,
                font_size_slider, position_select, subtitle_offset_x, subtitle_offset_y,
                use_subtitle_bg, subtitle_bg_opacity, subtitle_bg_padding, tts_file
            ],
            outputs=[audio_output, video_output, status_output, download_file]
        )

    return demo


# ì•± ì‹œì‘
if __name__ == '__main__':
    print("=" * 50)
    print("Supertonic TTS + Video (Gradio ë²„ì „)")
    print("=" * 50)
    print(f"ì¶œë ¥ í´ë”: {OUTPUT_DIR}")
    print("=" * 50)

    # TTS ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ (CPU ëª¨ë“œ)
    init_tts()

    # Gradio ì•± ì‹œì‘
    demo = create_ui()
    demo.launch(server_name="0.0.0.0", server_port=7860, share=True)
